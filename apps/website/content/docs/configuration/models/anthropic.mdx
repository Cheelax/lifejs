---
title: Anthropic
description: Configure Anthropic Claude models for large language model inference
---

## Anthropic Provider

The Anthropic provider enables you to use Claude models, including the latest Claude 3.5 Sonnet and Haiku, in your Life.js agent.

### Configuration

```typescript
import { Agent } from "life/agent";

const agent = new Agent({
  llm: {
    provider: "anthropic",
    apiKey: "sk-...", // Or set ANTHROPIC_API_KEY environment variable
    model: "claude-3-5-sonnet-20241022", // Default model
    temperature: 0.5, // Controls randomness (0.0 to 1.0)
    maxTokens: 4096, // Maximum tokens to generate (1 to 8192)
  },
  // ... other config
});
```

### Environment Variables

Set your Anthropic API key as an environment variable:

```bash
export ANTHROPIC_API_KEY="sk-..."
```

### Available Models

| Model | Description |
|-------|-------------|
| `claude-3-5-sonnet-20241022` | Most intelligent model, best for complex tasks (default) |
| `claude-3-5-haiku-20241022` | Fast and cost-effective for everyday tasks |
| `claude-3-opus-20240229` | Powerful model for highly complex tasks |
| `claude-3-sonnet-20240229` | Balanced performance for general use |
| `claude-3-haiku-20240307` | Fastest model for simple tasks |

### Configuration Schema

```typescript
{
  apiKey: string;        // Anthropic API key (required)
  model: string;         // Model name (see table above)
  temperature: number;   // 0.0 to 1.0, controls randomness
  maxTokens: number;     // 1 to 8192, maximum tokens to generate
}
```

### Features

- ✅ Chat completions
- ✅ Streaming responses
- ✅ Function/tool calling
- ✅ Structured output generation
- ✅ System prompts
- ✅ Vision capabilities (all models)
- ✅ Long context windows (up to 200K tokens)

### Getting Started

1. **Get your API key**: Visit [console.anthropic.com](https://console.anthropic.com) to obtain your Anthropic API key
2. **Set environment variable**: `export ANTHROPIC_API_KEY="your-key-here"`
3. **Configure your agent**: Use the configuration example above
4. **Start building**: Your agent is now ready to use Claude models!

### Example Usage

```typescript
import { Agent } from "life/agent";

const agent = new Agent({
  llm: {
    provider: "anthropic",
    model: "claude-3-5-sonnet-20241022",
    temperature: 0.7,
    maxTokens: 2048,
  },
});

// The agent will now use Anthropic Claude models for all LLM operations
```

### Model Selection Guide

- **claude-3-5-sonnet**: Best overall model with superior intelligence, speed, and cost-effectiveness
- **claude-3-5-haiku**: Fastest model for high-volume, simple tasks with excellent cost efficiency
- **claude-3-opus**: Most capable for highly complex analysis and creative tasks
- **claude-3-sonnet**: Good balance of capability and speed for general tasks
- **claude-3-haiku**: Ultra-fast responses for straightforward queries

### Context Windows

All Claude models support large context windows:
- Claude 3.5 models: 200K tokens
- Claude 3 models: 200K tokens

This allows for processing long documents, extensive conversations, and complex multi-step reasoning tasks.